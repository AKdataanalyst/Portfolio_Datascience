{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Waze Project**\n",
    "**Course 5 - Regression analysis: Simplify complex data relationships**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaOj1equPMAb"
   },
   "source": [
    "Your team is more than halfway through their user churn project. Earlier, you completed a project proposal, used Python to explore and analyze Wazeâ€™s user data, created data visualizations, and conducted a hypothesis test. Now, leadership wants your team to build a regression model to predict user churn based on a variety of variables.\n",
    "\n",
    "You check your inbox and discover a new email from Ursula Sayo, Waze's Operations Manager. Ursula asks your team about the details of the regression model. You also notice two follow-up emails from your supervisor, May Santner. The first email is a response to Ursula, and says that the team will build a binomial logistic regression model. In her second email, May asks you to help build the model and prepare an executive summary to share your results.\n",
    "\n",
    "A notebook was structured and prepared to help you in this project. Please complete the following questions and prepare an executive summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# **Course 5 End-of-course project: Regression modeling**\n",
    "\n",
    "In this activity, you will build a binomial logistic regression model. As you have learned, logistic regression helps you estimate the probability of an outcome. For data science professionals, this is a useful skill because it allows you to consider more than one variable against the variable you're measuring against. This opens the door for much more thorough and flexible analysis to be completed.\n",
    "<br/>\n",
    "\n",
    "**The purpose** of this project is to demostrate knowledge of exploratory data analysis (EDA) and a binomial logistic regression model.\n",
    "\n",
    "**The goal** is to build a binomial logistic regression model and evaluate the model's performance.\n",
    "<br/>\n",
    "\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** EDA & Checking Model Assumptions\n",
    "* What are some purposes of EDA before constructing a binomial logistic regression model?\n",
    "\n",
    "**Part 2:** Model Building and Evaluation\n",
    "* What resources do you find yourself using as you complete this stage?\n",
    "\n",
    "**Part 3:** Interpreting Model Results\n",
    "\n",
    "* What key insights emerged from your model(s)?\n",
    "\n",
    "* What business recommendations do you propose based on the models built?\n",
    "\n",
    "<br/>\n",
    "\n",
    "Follow the instructions and answer the question below to complete the activity. Then, you will complete an executive summary using the questions listed on the PACE Strategy Document.\n",
    "\n",
    "Be sure to complete this activity before moving on. The next course item will provide you with a completed exemplar to compare to your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L5F-G_cfLWL"
   },
   "source": [
    "# **Build a regression model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UCHQclzQDUL"
   },
   "source": [
    "<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "# **PACE stages**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lzafIgkjrdR"
   },
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5O5cx_qQJmX"
   },
   "source": [
    "<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "\n",
    "## **PACE: Plan**\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Plan stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8qYlvkLQsf2"
   },
   "source": [
    "### **Task 1. Imports and data loading**\n",
    "Import the data and packages that you've learned are needed for building logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "id": "ccfeg6X6eOVZ"
   },
   "outputs": [],
   "source": [
    "# Packages for numerics + dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Packages for Logistic Regression & Confusion Matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjljvyG32kqe"
   },
   "source": [
    "Import the dataset.\n",
    "\n",
    "**Note:** As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "id": "TyR3sBUYJBO8"
   },
   "outputs": [],
   "source": [
    "# Load the dataset by running this cell\n",
    "\n",
    "df = pd.read_csv('waze_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnrvCSfHUWPv"
   },
   "source": [
    "<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Analyze**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Analyze stage.\n",
    "\n",
    "In this stage, consider the following question:\n",
    "\n",
    "* What are some purposes of EDA before constructing a binomial logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgK-IOSRO4Sh"
   },
   "source": [
    "==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIcDG2e66wt9"
   },
   "source": [
    "### **Task 2a. Explore data with EDA**\n",
    "\n",
    "Analyze and discover data, looking for correlations, missing data, potential outliers, and/or duplicates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "offDH5p62x73"
   },
   "source": [
    "Start with `.shape` and `info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "id": "T4Ag-sZhWg6K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999, 13)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       14999 non-null  int64  \n",
      " 1   label                    14299 non-null  object \n",
      " 2   sessions                 14999 non-null  int64  \n",
      " 3   drives                   14999 non-null  int64  \n",
      " 4   total_sessions           14999 non-null  float64\n",
      " 5   n_days_after_onboarding  14999 non-null  int64  \n",
      " 6   total_navigations_fav1   14999 non-null  int64  \n",
      " 7   total_navigations_fav2   14999 non-null  int64  \n",
      " 8   driven_km_drives         14999 non-null  float64\n",
      " 9   duration_minutes_drives  14999 non-null  float64\n",
      " 10  activity_days            14999 non-null  int64  \n",
      " 11  driving_days             14999 non-null  int64  \n",
      " 12  device                   14999 non-null  object \n",
      "dtypes: float64(3), int64(8), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut0mWpGG6mkh"
   },
   "source": [
    "**Question:** Are there any missing values in your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSZgL1Eseep6"
   },
   "source": [
    "Missing values are there in labels columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCNi5-Ur2_en"
   },
   "source": [
    "Use `.head()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "id": "ll2pxoClXgmx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>retained</td>\n",
       "      <td>283</td>\n",
       "      <td>226</td>\n",
       "      <td>296.748273</td>\n",
       "      <td>2276</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2628.845068</td>\n",
       "      <td>1985.775061</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>retained</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>326.896596</td>\n",
       "      <td>1225</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>13715.920550</td>\n",
       "      <td>3160.472914</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>retained</td>\n",
       "      <td>114</td>\n",
       "      <td>95</td>\n",
       "      <td>135.522926</td>\n",
       "      <td>2651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3059.148818</td>\n",
       "      <td>1610.735904</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>retained</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>67.589221</td>\n",
       "      <td>15</td>\n",
       "      <td>322</td>\n",
       "      <td>7</td>\n",
       "      <td>913.591123</td>\n",
       "      <td>587.196542</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>retained</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>168.247020</td>\n",
       "      <td>1562</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>3950.202008</td>\n",
       "      <td>1219.555924</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     label  sessions  drives  total_sessions  n_days_after_onboarding  \\\n",
       "0   0  retained       283     226      296.748273                     2276   \n",
       "1   1  retained       133     107      326.896596                     1225   \n",
       "2   2  retained       114      95      135.522926                     2651   \n",
       "3   3  retained        49      40       67.589221                       15   \n",
       "4   4  retained        84      68      168.247020                     1562   \n",
       "\n",
       "   total_navigations_fav1  total_navigations_fav2  driven_km_drives  \\\n",
       "0                     208                       0       2628.845068   \n",
       "1                      19                      64      13715.920550   \n",
       "2                       0                       0       3059.148818   \n",
       "3                     322                       7        913.591123   \n",
       "4                     166                       5       3950.202008   \n",
       "\n",
       "   duration_minutes_drives  activity_days  driving_days   device  \n",
       "0              1985.775061             28            19  Android  \n",
       "1              3160.472914             13            11   iPhone  \n",
       "2              1610.735904             14             8  Android  \n",
       "3               587.196542              7             3   iPhone  \n",
       "4              1219.555924             27            18  Android  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT1h-utWs7ow"
   },
   "source": [
    "Use `.drop()` to remove the ID column since we don't need this information for your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "id": "CZK6D8kls9cj"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID'])\n",
    "df.dropna(axis = 0 , inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXn6VVNO7ArZ"
   },
   "source": [
    "Now, check the class balance of the dependent (target) variable, `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "id": "UCN_-mH87DwP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sessions</th>\n",
       "      <th>drives</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>n_days_after_onboarding</th>\n",
       "      <th>total_navigations_fav1</th>\n",
       "      <th>total_navigations_fav2</th>\n",
       "      <th>driven_km_drives</th>\n",
       "      <th>duration_minutes_drives</th>\n",
       "      <th>activity_days</th>\n",
       "      <th>driving_days</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retained</td>\n",
       "      <td>283</td>\n",
       "      <td>226</td>\n",
       "      <td>296.748273</td>\n",
       "      <td>2276</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2628.845068</td>\n",
       "      <td>1985.775061</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>retained</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>326.896596</td>\n",
       "      <td>1225</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>13715.920550</td>\n",
       "      <td>3160.472914</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retained</td>\n",
       "      <td>114</td>\n",
       "      <td>95</td>\n",
       "      <td>135.522926</td>\n",
       "      <td>2651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3059.148818</td>\n",
       "      <td>1610.735904</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>retained</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>67.589221</td>\n",
       "      <td>15</td>\n",
       "      <td>322</td>\n",
       "      <td>7</td>\n",
       "      <td>913.591123</td>\n",
       "      <td>587.196542</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>retained</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>168.247020</td>\n",
       "      <td>1562</td>\n",
       "      <td>166</td>\n",
       "      <td>5</td>\n",
       "      <td>3950.202008</td>\n",
       "      <td>1219.555924</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  sessions  drives  total_sessions  n_days_after_onboarding  \\\n",
       "0  retained       283     226      296.748273                     2276   \n",
       "1  retained       133     107      326.896596                     1225   \n",
       "2  retained       114      95      135.522926                     2651   \n",
       "3  retained        49      40       67.589221                       15   \n",
       "4  retained        84      68      168.247020                     1562   \n",
       "\n",
       "   total_navigations_fav1  total_navigations_fav2  driven_km_drives  \\\n",
       "0                     208                       0       2628.845068   \n",
       "1                      19                      64      13715.920550   \n",
       "2                       0                       0       3059.148818   \n",
       "3                     322                       7        913.591123   \n",
       "4                     166                       5       3950.202008   \n",
       "\n",
       "   duration_minutes_drives  activity_days  driving_days   device  \n",
       "0              1985.775061             28            19  Android  \n",
       "1              3160.472914             13            11   iPhone  \n",
       "2              1610.735904             14             8  Android  \n",
       "3               587.196542              7             3   iPhone  \n",
       "4              1219.555924             27            18  Android  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcEIBLGcIbGa"
   },
   "source": [
    "Call `.describe()` on the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "id": "AjcSoFeVIhYf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14299 entries, 0 to 14998\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   label                    14299 non-null  object \n",
      " 1   sessions                 14299 non-null  int64  \n",
      " 2   drives                   14299 non-null  int64  \n",
      " 3   total_sessions           14299 non-null  float64\n",
      " 4   n_days_after_onboarding  14299 non-null  int64  \n",
      " 5   total_navigations_fav1   14299 non-null  int64  \n",
      " 6   total_navigations_fav2   14299 non-null  int64  \n",
      " 7   driven_km_drives         14299 non-null  float64\n",
      " 8   duration_minutes_drives  14299 non-null  float64\n",
      " 9   activity_days            14299 non-null  int64  \n",
      " 10  driving_days             14299 non-null  int64  \n",
      " 11  device                   14299 non-null  object \n",
      "dtypes: float64(3), int64(7), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.describe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3EPwXZH7KnT"
   },
   "source": [
    "**Question:** Are there any variables that could potentially have outliers just by assessing at the quartile values, standard deviation, and max values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjmTTz3YfgmA"
   },
   "source": [
    "==> driven_km_drives has outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl8G_0FR6Rvk"
   },
   "source": [
    "### **Task 2b. Create features**\n",
    "\n",
    "Create features that may be of interest to the stakeholder and/or that are needed to address the business scenario/problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKkx6FvS4OpI"
   },
   "source": [
    "#### **`km_per_driving_day`**\n",
    "\n",
    "You know from earlier EDA that churn rate correlates with distance driven per driving day in the last month. It might be helpful to engineer a feature that captures this information.\n",
    "\n",
    "1. Create a new column in `df` called `km_per_driving_day`, which represents the mean distance driven per driving day for each user.\n",
    "\n",
    "2. Call the `describe()` method on the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "id": "KCEzE-gwL5gq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14299.000000\n",
       "mean      4044.401535\n",
       "std       2504.977970\n",
       "min         60.441250\n",
       "25%       2217.319909\n",
       "50%       3496.545617\n",
       "75%       5299.972162\n",
       "max      21183.401890\n",
       "Name: driven_km_drives, dtype: float64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create `km_per_driving_day` column\n",
    "df['km_per_driving_day'] = df['driven_km_drives'] / df['driving_days']\n",
    "\n",
    "\n",
    "\n",
    "# 2. Call `describe()` on the new column\n",
    "df['km_per_driving_day'].describe()\n",
    "df['driven_km_drives'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ldmks6g4ZzE"
   },
   "source": [
    "Note that some values are infinite. This is the result of there being values of zero in the `driving_days` column. Pandas imputes a value of infinity in the corresponding rows of the new column because division by zero is undefined.\n",
    "\n",
    "1. Convert these values from infinity to zero. You can use `np.inf` to refer to a value of infinity.\n",
    "\n",
    "2. Call `describe()` on the `km_per_driving_day` column to verify that it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "id": "FetTHatPoR6n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14299.000000\n",
       "mean       581.942399\n",
       "std       1038.254509\n",
       "min          0.000000\n",
       "25%        136.168003\n",
       "50%        273.301012\n",
       "75%        558.018761\n",
       "max      15420.234110\n",
       "Name: km_per_driving_day, dtype: float64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert infinite values to zero\n",
    "df['km_per_driving_day'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# 2. Confirm that it worked\n",
    "df['km_per_driving_day'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky5h_Aum3RK1"
   },
   "source": [
    "#### **`professional_driver`**\n",
    "\n",
    "Create a new, binary feature called `professional_driver` that is a 1 for users who had 60 or more drives <u>**and**</u> drove on 15+ days in the last month.\n",
    "\n",
    "**Note:** The objective is to create a new feature that separates professional drivers from other drivers. In this scenario, domain knowledge and intuition are used to determine these deciding thresholds, but ultimately they are arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml0Y6mb--HD5"
   },
   "source": [
    "To create this column, use the [`np.where()`](https://numpy.org/doc/stable/reference/generated/numpy.where.html) function. This function accepts as arguments:\n",
    "1. A condition\n",
    "2. What to return when the condition is true\n",
    "3. What to return when the condition is false\n",
    "\n",
    "```\n",
    "Example:\n",
    "x = [1, 2, 3]\n",
    "x = np.where(x > 2, 100, 0)\n",
    "x\n",
    "array([  0,   0, 100])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "id": "huWmzNp2Xj8o"
   },
   "outputs": [],
   "source": [
    "# Create `professional_driver` column\n",
    "import numpy as np\n",
    "\n",
    "df['professional driver'] = np.where((df['drives'] >= 60) & (df['driving_days'] > 15), 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sq1WCqLmaHSU"
   },
   "source": [
    "Perform a quick inspection of the new variable.\n",
    "\n",
    "1. Check the count of professional drivers and non-professionals\n",
    "\n",
    "2. Within each class (professional and non-professional) calculate the churn rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "id": "jCAvucIVa3jE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label     professional driver\n",
      "churned   0                      2375\n",
      "          1                       161\n",
      "retained  0                      9640\n",
      "          1                      2123\n",
      "Name: professional driver, dtype: int64\n",
      "Churn for professional drivers : 7.583608101742817 %\n",
      "Churn for non -professional drivers : 24.636929460580916 %\n",
      "label     professional driver\n",
      "churned   0                      2.287360e+06\n",
      "          1                      3.098769e+04\n",
      "retained  0                      5.576649e+06\n",
      "          1                      4.261979e+05\n",
      "Name: km_per_driving_day, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Check count of professionals and non-professionals\n",
    "df['professional driver'].value_counts()\n",
    "\n",
    "# 2. Check in-class churn rate\n",
    "result = df.groupby('label')['professional driver'].value_counts()\n",
    "print(result)\n",
    "\n",
    "churn_prof = 161/2123\n",
    "churn_non_prof = 2375/9640\n",
    "print('Churn for professional drivers : ' + str((churn_prof)*100) + ' %')\n",
    "\n",
    "print('Churn for non -professional drivers : ' + str((churn_non_prof)*100) + ' %')\n",
    "\n",
    "\n",
    "result2 = df.groupby(['label','professional driver'])['km_per_driving_day'].sum()\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7kHbF4m-ZXA"
   },
   "source": [
    "The churn rate for professional drivers is 7.6%, while the churn rate for non-professionals is 19.9%. This seems like it could add predictive signal to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgPul2DiY6T4"
   },
   "source": [
    "<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Construct**\n",
    "\n",
    "After analysis and deriving variables with close relationships, it is time to begin constructing the model.\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Construct stage.\n",
    "\n",
    "In this stage, consider the following question:\n",
    "\n",
    "* Why did you select the X variables you did?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZi2G9pkQ_kM"
   },
   "source": [
    "==> 'km_per_driving_day'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07UJJm41ajgf"
   },
   "source": [
    "### **Task 3a. Preparing variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aanTG0VxniQh"
   },
   "source": [
    "Call `info()` on the dataframe to check the data type of the `label` variable and to verify if there are any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "id": "tHFNCNj3ob30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14299 entries, 0 to 14998\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   label                    14299 non-null  object \n",
      " 1   sessions                 14299 non-null  int64  \n",
      " 2   drives                   14299 non-null  int64  \n",
      " 3   total_sessions           14299 non-null  float64\n",
      " 4   n_days_after_onboarding  14299 non-null  int64  \n",
      " 5   total_navigations_fav1   14299 non-null  int64  \n",
      " 6   total_navigations_fav2   14299 non-null  int64  \n",
      " 7   driven_km_drives         14299 non-null  float64\n",
      " 8   duration_minutes_drives  14299 non-null  float64\n",
      " 9   activity_days            14299 non-null  int64  \n",
      " 10  driving_days             14299 non-null  int64  \n",
      " 11  device                   14299 non-null  object \n",
      " 12  km_per_driving_day       14299 non-null  float64\n",
      " 13  professional driver      14299 non-null  int64  \n",
      "dtypes: float64(4), int64(8), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J90QgkTrofOC"
   },
   "source": [
    "Because you know from previous EDA that there is no evidence of a non-random cause of the 700 missing values in the `label` column, and because these observations comprise less than 5% of the data, use the `dropna()` method to drop the rows that are missing this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "id": "B34fDk52o2Uk"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing data in `label` column\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV3KLq7LpcWB"
   },
   "source": [
    "#### **Impute outliers**\n",
    "\n",
    "You rarely want to drop outliers, and generally will not do so unless there is a clear reason for it (e.g., typographic errors).\n",
    "\n",
    "At times outliers can be changed to the **median, mean, 95th percentile, etc.**\n",
    "\n",
    "Previously, you determined that seven of the variables had clear signs of containing outliers:\n",
    "\n",
    "* `sessions`\n",
    "* `drives`\n",
    "* `total_sessions`\n",
    "* `total_navigations_fav1`\n",
    "* `total_navigations_fav2`\n",
    "* `driven_km_drives`\n",
    "* `duration_minutes_drives`\n",
    "\n",
    "For this analysis, impute the outlying values for these columns. Calculate the **95th percentile** of each column and change to this value any value in the column that exceeds it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "id": "7fRaU2JKpyXg"
   },
   "outputs": [],
   "source": [
    "# Impute outliers\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90s91HTOAqnT"
   },
   "source": [
    "Call `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "id": "aU13ZoCMAN_s"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9dLJfBHAxNy"
   },
   "source": [
    "#### **Encode categorical variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RksGqJI3A7L9"
   },
   "source": [
    "Change the data type of the `label` column to be binary. This change is needed to train a logistic regression model.\n",
    "\n",
    "Assign a `0` for all `retained` users.\n",
    "\n",
    "Assign a `1` for all `churned` users.\n",
    "\n",
    "Save this variable as `label2` as to not overwrite the original `label` variable.\n",
    "\n",
    "**Note:** There are many ways to do this. Consider using `np.where()` as you did earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "id": "XvcP3FxpAyws"
   },
   "outputs": [],
   "source": [
    "# Create binary `label2` column\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMj6QkK1cLmS"
   },
   "source": [
    "### **Task 3b. Determine whether assumptions have been met**\n",
    "\n",
    "The following are the assumptions for logistic regression:\n",
    "\n",
    "* Independent observations (This refers to how the data was collected.)\n",
    "\n",
    "* No extreme outliers\n",
    "\n",
    "* Little to no multicollinearity among X predictors\n",
    "\n",
    "* Linear relationship between X and the **logit** of y\n",
    "\n",
    "For the first assumption, you can assume that observations are independent for this project.\n",
    "\n",
    "The second assumption has already been addressed.\n",
    "\n",
    "The last assumption will be verified after modeling.\n",
    "\n",
    "**Note:** In practice, modeling assumptions are often violated, and depending on the specifics of your use case and the severity of the violation, it might not affect your model much at all or it will result in a failed model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VByuTmwdoi_"
   },
   "source": [
    "#### **Collinearity**\n",
    "\n",
    "Check the correlation among predictor variables. First, generate a correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "SClNm5hWotj6"
   },
   "outputs": [],
   "source": [
    "# Generate a correlation matrix\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maeFcfOMfi1V"
   },
   "source": [
    "Now, plot a correlation heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "id": "5HVnvWmXrOCO"
   },
   "outputs": [],
   "source": [
    "# Plot correlation heatmap\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wvq6jl6BqBX"
   },
   "source": [
    "If there are predictor variables that have a Pearson correlation coefficient value greater than the **absolute value of 0.7**, these variables are strongly multicollinear. Therefore, only one of these variables should be used in your model.\n",
    "\n",
    "**Note:** 0.7 is an arbitrary threshold. Some industries may use 0.6, 0.8, etc.\n",
    "\n",
    "**Question:** Which variables are multicollinear with each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfkKRuFSgmiI"
   },
   "source": [
    "==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3ArC_5xa7Oi"
   },
   "source": [
    "### **Task 3c. Create dummies (if necessary)**\n",
    "\n",
    "If you have selected `device` as an X variable, you will need to create dummy variables since this variable is categorical.\n",
    "\n",
    "In cases with many categorical variables, you can use pandas built-in [`pd.get_dummies()`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html), or you can use scikit-learn's [`OneHotEncoder()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) function.\n",
    "\n",
    "**Note:** Variables with many categories should only be dummied if absolutely necessary. Each category will result in a coefficient for your model which can lead to overfitting.\n",
    "\n",
    "Because this dataset only has one remaining categorical feature (`device`), it's not necessary to use one of these special functions. You can just implement the transformation directly.\n",
    "\n",
    "Create a new, binary column called `device2` that encodes user devices as follows:\n",
    "\n",
    "* `Android` -> `0`\n",
    "* `iPhone` -> `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "id": "QvDpwcQm0f35"
   },
   "outputs": [],
   "source": [
    "# Create new `device2` variable\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDYyjWssbnBG"
   },
   "source": [
    "### **Task 3d. Model building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvmcjB19Cpw-"
   },
   "source": [
    "#### **Assign predictor variables and target**\n",
    "\n",
    "To build your model you need to determine what X variables you want to include in your model to predict your target&mdash;`label2`.\n",
    "\n",
    "Drop the following variables and assign the results to `X`:\n",
    "\n",
    "* `label` (this is the target)\n",
    "* `label2` (this is the target)\n",
    "* `device` (this is the non-binary-encoded categorical variable)\n",
    "* `sessions` (this had high multicollinearity)\n",
    "* `driving_days` (this had high multicollinearity)\n",
    "\n",
    "**Note:** Notice that `sessions` and `driving_days` were selected to be dropped, rather than `drives` and `activity_days`. The reason for this is that the features that were kept for modeling had slightly stronger correlations with the target variable than the features that were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "id": "AzcDgLRET4d7"
   },
   "outputs": [],
   "source": [
    "# Isolate predictor variables\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c1Dzcz6C3WR"
   },
   "source": [
    "Now, isolate the dependent (target) variable. Assign it to a variable called `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "id": "h0QFCHIJC3-I"
   },
   "outputs": [],
   "source": [
    "# Isolate target variable\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOewKY740Beq"
   },
   "source": [
    "#### **Split the data**\n",
    "\n",
    "Use scikit-learn's [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to perform a train/test split on your data using the X and y variables you assigned above.\n",
    "\n",
    "**Note 1:** It is important to do a train test to obtain accurate predictions.  You always want to fit your model on your training set and evaluate your model on your test set to avoid data leakage.\n",
    "\n",
    "**Note 2:** Because the target class is imbalanced (82% retained vs. 18% churned), you want to make sure that you don't get an unlucky split that over- or under-represents the frequency of the minority class. Set the function's `stratify` parameter to `y` to ensure that the minority class appears in both train and test sets in the same proportion that it does in the overall dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "id": "ulDZdfSS0FyD"
   },
   "outputs": [],
   "source": [
    "# Perform the train-test split\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "id": "Q1vdmEo3mKmO"
   },
   "outputs": [],
   "source": [
    "# Use .head()\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMUo8Ri-zK7r"
   },
   "source": [
    "Use scikit-learn to instantiate a logistic regression model. Add the argument `penalty = None`.\n",
    "\n",
    "It is important to add `penalty = None` since your predictors are unscaled.\n",
    "\n",
    "Refer to scikit-learn's [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) documentation for more information.\n",
    "\n",
    "Fit the model on `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "id": "zrTNaDVZheyp"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPoDllWB6ULV"
   },
   "source": [
    "Call the `.coef_` attribute on the model to get the coefficients of each variable.  The coefficients are in order of how the variables are listed in the dataset.  Remember that the coefficients represent the change in the **log odds** of the target variable for **every one unit increase in X**.\n",
    "\n",
    "If you want, create a series whose index is the column names and whose values are the coefficients in `model.coef_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "id": "7Ri-OHrlmd8j"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ENmLXXp8JDM"
   },
   "source": [
    "Call the model's `intercept_` attribute to get the intercept of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "id": "hWeruvy1wksj"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdVIjKNHmlY_"
   },
   "source": [
    "#### **Check final assumption**\n",
    "\n",
    "Verify the linear relationship between X and the estimated log odds (known as logits) by making a regplot.\n",
    "\n",
    "Call the model's `predict_proba()` method to generate the probability of response for each sample in the training data. (The training data is the argument to the method.) Assign the result to a variable called `training_probabilities`. This results in a 2-D array where each row represents a user in `X_train`. The first column is the probability of the user not churning, and the second column is the probability of the user churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "id": "aY71xhehmo9i"
   },
   "outputs": [],
   "source": [
    "# Get the predicted probabilities of the training data\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AGMCvdfmpfU"
   },
   "source": [
    "In logistic regression, the relationship between a predictor variable and the dependent variable does not need to be linear, however, the log-odds (a.k.a., logit) of the dependent variable with respect to the predictor variable should be linear. Here is the formula for calculating log-odds, where _p_ is the probability of response:\n",
    "<br>\n",
    "$$\n",
    "logit(p) = ln(\\frac{p}{1-p})\n",
    "$$\n",
    "<br>\n",
    "\n",
    "1. Create a dataframe called `logit_data` that is a copy of `df`.\n",
    "\n",
    "2. Create a new column called `logit` in the `logit_data` dataframe. The data in this column should represent the logit for each user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "id": "-tXq8gYnEw6M"
   },
   "outputs": [],
   "source": [
    "# 1. Copy the `X_train` dataframe and assign to `logit_data`\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# 2. Create a new `logit` column in the `logit_data` df\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6oVbApcEx71"
   },
   "source": [
    "Plot a regplot where the x-axis represents an independent variable and the y-axis represents the log-odds of the predicted probabilities.\n",
    "\n",
    "In an exhaustive analysis, this would be plotted for each continuous or discrete predictor variable. Here we show only `driving_days`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "id": "5ix8VT0VEzQK"
   },
   "outputs": [],
   "source": [
    "# Plot regplot of `activity_days` log-odds\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp7ojoBldEYy"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## **PACE: Execute**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Execute stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_l3bkxQdJ3a"
   },
   "source": [
    "### **Task 4a. Results and evaluation**\n",
    "\n",
    "If the logistic assumptions are met, the model results can be appropriately interpreted.\n",
    "\n",
    "Use the code block below to make predictions on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "id": "cSl5gbXfBPBN"
   },
   "outputs": [],
   "source": [
    "# Generate predictions on X_test\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbN_LHUb9uhp"
   },
   "source": [
    "Now, use the `score()` method on the model with `X_test` and `y_test` as its two arguments. The default score in scikit-learn is **accuracy**.  What is the accuracy of your model?\n",
    "\n",
    "*Consider:  Is accuracy the best metric to use to evaluate this model?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "id": "fU3v-XO49qm8"
   },
   "outputs": [],
   "source": [
    "# Score the model (accuracy) on the test data\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwRmSDS3eyeH"
   },
   "source": [
    "### **Task 4b. Show results with a confusion matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUKLVt50-zFE"
   },
   "source": [
    "Use the `confusion_matrix` function to obtain a confusion matrix. Use `y_test` and `y_preds` as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "id": "IBFU_dicBjwQ"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKS_DsNcGotN"
   },
   "source": [
    "Next, use the `ConfusionMatrixDisplay()` function to display the confusion matrix from the above cell, passing the confusion matrix you just created as its argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "id": "BT0hOH_ZFsnx"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkqTjhWotVCK"
   },
   "source": [
    "You can use the confusion matrix to compute precision and recall manually. You can also use scikit-learn's [`classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) function to generate a table from `y_test` and `y_preds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "id": "39RM-g6UtbJ_"
   },
   "outputs": [],
   "source": [
    "# Calculate precision manually\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "xUy7TDpHGlOf"
   },
   "outputs": [],
   "source": [
    "# Calculate recall manually\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "id": "jTxfglLMGlr_"
   },
   "outputs": [],
   "source": [
    "# Create a classification report\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8FQnyhnHFT7"
   },
   "source": [
    "**Note:** The model has decent precision but very low recall, which means that it makes a lot of false negative predictions and fails to capture users who will churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSpkqurtHJSE"
   },
   "source": [
    "### **BONUS**\n",
    "\n",
    "Generate a bar graph of the model's coefficients for a visual representation of the importance of the model's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "id": "tuT0aP6FHL6B"
   },
   "outputs": [],
   "source": [
    "# Create a list of (column_name, coefficient) tuples\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Sort the list by coefficient value\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "id": "kaam2OD8HOP5"
   },
   "outputs": [],
   "source": [
    "# Plot the feature importances\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6AlDDyhdzmG"
   },
   "source": [
    "### **Task 4c. Conclusion**\n",
    "\n",
    "Now that you've built your regression model, the next step is to share your findings with the Waze leadership team. Consider the following questions as you prepare to write your executive summary. Think about key points you may want to share with the team, and what information is most relevant to the user churn project.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. What variable most influenced the model's prediction? How? Was this surprising?\n",
    "\n",
    "2. Were there any variables that you expected to be stronger predictors than they were?\n",
    "\n",
    "3. Why might a variable you thought to be important not be important in the model?\n",
    "\n",
    "4. Would you recommend that Waze use this model? Why or why not?\n",
    "\n",
    "5. What could you do to improve this model?\n",
    "\n",
    "6. What additional features would you like to have to help improve the model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTs79FvvT9It"
   },
   "source": [
    "==> ENTER YOUR RESPONSES TO QUESTIONS 1-6 HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "10VdUGxtn9_2OaVJAptrlOkngf4ZKm52V",
     "timestamp": 1671215458572
    },
    {
     "file_id": "1Et0HEKWEY0dZ0BaNZeH189bi-PnC-iUH",
     "timestamp": 1671209438879
    },
    {
     "file_id": "16ynSVRiYFz40jV9BFaXgY62vWJWEVjFA",
     "timestamp": 1671052218770
    },
    {
     "file_id": "15PPfvGb4OuUkuQoTTpKKgSeY9o9a_XrL",
     "timestamp": 1669649625868
    },
    {
     "file_id": "1_uBujapIzHItho27E-iPg9wn3aHtsjLG",
     "timestamp": 1664565386285
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
